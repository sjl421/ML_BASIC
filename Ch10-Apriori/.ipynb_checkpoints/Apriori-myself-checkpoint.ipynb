{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 Apriori 算法进行关联分析\n",
    "\n",
    "内容安排\n",
    "1. 关联分析相关概念\n",
    "2. Apriori 算法原理和实现\n",
    "3. 两个示例\n",
    "\n",
    "## 1. 关联分析\n",
    "\n",
    "**关联分析**：一种在大规模数据集中寻找隐含的有趣关系的任务。这些关系有两种形式：**频繁项集**和**关联规则**\n",
    "\n",
    "### 1.1 用示例对概念进行说明\n",
    "\n",
    "给出一个商店的交易清单，如下表显示\n",
    "\n",
    "|交易编号|商品|\n",
    "|--|--|\n",
    "|0|豆奶，莴苣|\n",
    "|1|莴苣，尿布，葡萄酒，甜菜|\n",
    "|2|豆奶，尿布，葡萄酒，橙汁|\n",
    "|3|莴苣，豆奶，葡萄酒，尿布|\n",
    "|4|莴苣，豆奶，尿布，橙汁|\n",
    "\n",
    "- **物品列表**：代表商店出售的所有商品的列表。\\['豆奶','莴苣','尿布','葡萄酒','甜菜','橙汁'\\]\n",
    "- **频繁项集**：经常出现在一块的物品的集合。例子中，其中一个频繁项集是 {'豆奶','尿布','葡萄酒'}\n",
    "- **关联规则**：两种物品之间可能存在很强的关系，一般从频繁项集中挖掘物品的关联规则。从上述的频繁项集和交易清单中，可以挖掘出一条 \"尿布-->葡萄酒\" 的关联规则，即如果有人买了尿布，那么他很可能也会买葡萄酒。\n",
    "\n",
    "一些量化指标：\n",
    "\n",
    "- **支持度**：某个项集在数据集中出现的频率，即在数据集中包含该项集的记录所占的比例。如下表有5条交易记录，其中有3条记录包含{'豆奶','尿布'}这项集。故此项集{'豆奶','尿布'}的支持度为3/5\n",
    "- **可信度/置信度**：指某条关联规则的可信程度。如 \"尿布-->葡萄酒\" 的可信度为75%，说明这条规则对其中 75% 的记录都适用。计算公式就是条件概率的计算公式。\n",
    "\n",
    "### 1.2 关联分析的过程：即从交易清单到物品列表，再到频繁项集、再到关联规则的过程\n",
    "\n",
    "1. **从交易清单到物品列表的过程**；\n",
    "2. **从物品列表到频繁项集**：将物品进行全组合形成候选项集（如{'豆奶','尿布'},{'豆奶','葡萄酒'},{'豆奶','尿布','葡萄酒'},...）,当某个候选项集的支持度超过一定的阈值，就称为频繁项集\n",
    "3. **从频繁项集到关联规则**：对每个频繁项集挖掘关联规则（如{'豆奶','尿布','葡萄酒'}的关联规则有 \"尿布-->葡萄酒\", \"豆奶,尿布-->葡萄酒\", \"葡萄酒-->尿布\",...），对每个关联规则计算可信度。\n",
    "\n",
    "### 1.3 引出 Apriori\n",
    "\n",
    "在第 2 步中，首先要对物品列表中的物品进行全组合，如果一共有 4 种商品，全组合得到的候选项集有 $2^4-1=15$ 个，然后计算每个候选项集的支持度，选出频繁项集。如果有 N 种商品，那么候选项集有 $2^N-1$ 个。候选项集的指数式增长，如果不采用一些策略，关联分析就没法实现了。\n",
    "\n",
    "有一种基于**Apriori原理**的算法解决了候选项集的指数式增长带来计算时间的增长。\n",
    "\n",
    "## 2. Apriori\n",
    "\n",
    "注：Apriori 算法原理很容易理解，但实现起来很难。\n",
    "\n",
    "### 2.1 Apriori 原理：理解为剪枝\n",
    "\n",
    "**Apriori 原理**：如果某个项集的支持度高于阈值（即该项集是频繁的），那么它的所有子集的支持度也高于阈值。如 {0,1} 的支持度高，那么它子集 {0},{1} 的支持度一定高。实际中，我们将 Apriori 原理反过来说：**「某个项集支持度低于阈值（即该项集非频繁），那么它的超集支持度一定低于阈值」**。\n",
    "\n",
    "**运用 Apriori 原理**：计算出 {0,1} 的支持度低于阈值，那么根据原理知道它的超集 {0,1,2},{0,1,3} 支持度一定很低，就不再计算 {0,1,2},{0,1,3} 及其超集的支持度。从而降低了计算量，避免了指数式的增长。可以理解为剪枝\n",
    "\n",
    "举个例子，物品列表为 \\[0,1,2,3\\] , 先构建第一层的候选项集 {01,02,03,12,13,23}。假设 {23} 的支持度低于阈值，即 {23} 是非频繁的；那么就删除候选项集再构建下一层候选项集 {012,013} , 而不构建 {023,123} 的原因是其子集 {23} 是非频繁的，那么他俩肯定也是非频繁的，所以就没必要构建。从而避免了候选项集的指数式增长。下图是例子的示意图（其中，每个圆形代表一个候选项集；黑色填充的代表非频繁项集，其超集也是非频繁的。）\n",
    "\n",
    "![生成频繁项集](./生成频繁项集的示例图.png)\n",
    "\n",
    "**运用场景**：有两个运用 Apriori 的场景\n",
    "1. 生成频繁项集\n",
    "2. 对每个频繁项集生成关联规则：如某个频繁项集 {0123} 可生成的关联规则如下图：![一个频繁项集生成关联规则的示例图](./一个频繁项集生成关联规则的示例图.png)\n",
    "\n",
    "### 2.2 Apriori 算法过程\n",
    "\n",
    "\n",
    "**总体思路**：\n",
    "1. 从数据集中得到物品列表\n",
    "2. **构建频繁项集**：从物品列表构建候选项集，根据支持度选出频繁项集，并使用 Apriori 进行剪枝\n",
    "3. **从频繁项集中挖掘关联规则**：对每个频繁项集生成关联规则，根据可信度选择高于阈值的关联规则\n",
    "\n",
    "### 2.2.1 构建频繁项集\n",
    "\n",
    "**总体思路**：图一的构建过程是一层一层的向下构建的。\n",
    "1. 构建物品列表 C1，其中 C1 也是大小为 1 的所有候选项集（即只有一个元素的项集）的集合\n",
    "2. 计算每个候选项集的支持度，将高于阈值的待选项集构成频繁项集的集合 L1 （运用了 Apriori 进行剪枝）\n",
    "3. L1 中每个待选项集两两组合形成大小为 2 的所有候选项集的集合 C2\n",
    "4. 再计算支持度，过滤掉低于阈值的待选项集，形成频繁项集的集合 L2\n",
    "5. 重复构建过滤操作，直到 Ck 没有候选项集结束\n",
    "\n",
    "**Ck 生成 Lk 的算法伪代码**：\n",
    "\n",
    "```\n",
    "对数据集中的每条交易记录 tran：\n",
    "    对每个候选项集 can：\n",
    "        如果 can 是 tran 一个子集：增加 can 的计数\n",
    "对于每个候选项集：\n",
    "    计算其支持度\n",
    "    如果其支持度高于阈值，则将该项集添加到频繁项集列表中\n",
    "return 频繁项集的列表\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset : [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
      "C1 : [frozenset({1}), frozenset({2}), frozenset({3}), frozenset({4}), frozenset({5})]\n",
      "L1 : [frozenset({1}), frozenset({2}), frozenset({3}), frozenset({5})]\n",
      "C1 support data :  {frozenset({1}): 0.5, frozenset({2}): 0.75, frozenset({3}): 0.75, frozenset({4}): 0.25, frozenset({5}): 0.75}\n"
     ]
    }
   ],
   "source": [
    "def createC1(dataset):\n",
    "    '''\n",
    "    从数据集中构建物品列表，即构建 C1 的过程\n",
    "    :param dataset: [list] 数据集，是个二维列表，每行存一条交易记录。如[[1,2,3],[2,4],[1,4],...]\n",
    "    :return : [list] 物品列表 C1，也是大小为 1 的所有候选项集的集合\n",
    "    '''\n",
    "    C1 = []\n",
    "    for tran in dataset:  # 遍历每条交易记录\n",
    "        for item in tran:  # 遍历每条交易记录中的物品\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    return list(map(frozenset, C1))  # 将每个物品冻结，不可改变\n",
    "\n",
    "\n",
    "def scanD(D, Ck, min_support):\n",
    "    '''\n",
    "    Ck 生成 Lk 的算法，即从待选项集的集合 Ck 生成频繁项集的集合 Lk\n",
    "    :param D: [list] 数据集，是个二维列表，每行存一条交易记录。如[[1,2,3],[2,4],[1,4],...]\n",
    "    :param Ck: [list] 大小为 k 的候选项集的集合\n",
    "    :parma min_support: [int] 最小支持度，用于高于最小支持度则为频繁项集\n",
    "    :return : [list] Lk 大小为 k 的频繁项集的集合\n",
    "              [dict] support_data 每个候选项集的支持度 key:候选项集，value：其支持度\n",
    "    '''\n",
    "    # 1. 统计每个候选项集在数据集出现的次数\n",
    "    count = {} \n",
    "    for tran in D:  # 遍历每条交易记录\n",
    "        for can in Ck:  # 遍历每个候选项集\n",
    "            if can.issubset(tran):  # 当前候选项集是不是当前交易记录的子集，即当前候选项集是不是出现在当前交易记录\n",
    "                count[can] = count.get(can, 0) + 1\n",
    "    \n",
    "    # 2. 计算每个候选项集的支持度，并生成 Lk\n",
    "    Lk = []\n",
    "    support_data = {}  # 每个候选项集的支持度\n",
    "    m = len(D)\n",
    "    for can in Ck:\n",
    "        can_support = count[can] / m\n",
    "        if can_support >= min_support:\n",
    "            Lk.append(can)\n",
    "        support_data[can] = can_support\n",
    "    return Lk, support_data\n",
    "\n",
    "dataset = [[1,3,4],[2,3,5],[1,2,3,5],[2,5]]\n",
    "C1 = createC1(dataset)\n",
    "D = list(map(set, dataset))  # 每条交易记录去重，我们不关心物品的数量\n",
    "L1, support_data = scanD(D, C1, 0.5)\n",
    "print('dataset :',dataset)\n",
    "print('C1 :', C1)\n",
    "print('L1 :', L1)\n",
    "print('C1 support data : ', support_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面是一次 \"从待选项集的集合 Ck 生成频繁项集的集合 Lk\" 的过程。Apriori 算法构建频繁项集是重复该过程，直至 Lk 没有频繁项集\n",
    "\n",
    "**完整 Apriori 算法**：\n",
    "```\n",
    "当集合中项的个数大于 0 时：\n",
    "    构建一个大小为 k 的候选项集的集合\n",
    "    根据上一步得到的候选项集的集合，求得大小为 k 的频繁项集的集合\n",
    "    保留频繁项集和支持度\n",
    "    k += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[frozenset({1}), frozenset({2}), frozenset({3}), frozenset({5})], [frozenset({1, 3}), frozenset({2, 3}), frozenset({2, 5}), frozenset({3, 5})], [frozenset({2, 3, 5})], []]\n",
      "{frozenset({1}): 0.5, frozenset({2}): 0.75, frozenset({3}): 0.75, frozenset({4}): 0.25, frozenset({5}): 0.75, frozenset({1, 2}): 0.25, frozenset({1, 3}): 0.5, frozenset({1, 5}): 0.25, frozenset({2, 3}): 0.5, frozenset({2, 5}): 0.75, frozenset({3, 5}): 0.5, frozenset({2, 3, 5}): 0.5}\n"
     ]
    }
   ],
   "source": [
    "def apriori_gen(Lk, k):\n",
    "    '''\n",
    "    根据上一层的频繁项集的集合构建 Ck\n",
    "    将频繁项集两两组合，形成新的候选项集的项集\n",
    "    :param Lk: [list] 频繁项集的集合\n",
    "    :param k: [int] \n",
    "    '''\n",
    "    retList = []\n",
    "    m = len(Lk)\n",
    "    # Lk 中的元素（即频繁项集）两两组合\n",
    "    for i in range(m): \n",
    "        for j in range(i+1, m):\n",
    "            # 细节处理：避免得到重复组合\n",
    "            L1 = list(Lk[i])[:k-2]\n",
    "            L2 = list(Lk[j])[:k-2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            if L1 == L2:\n",
    "                retList.append(Lk[i]|Lk[j])\n",
    "    return retList\n",
    "\n",
    "def apriori(dataset, min_support=0.5):\n",
    "    '''\n",
    "    完整 Apriori 算法\n",
    "    :param dataset: [list] 数据集，是个二维列表，每行存一条交易记录。如[[1,2,3],[2,4],[1,4],...]\n",
    "    :param min_support: [int] 最小支持度，用于高于最小支持度则为频繁项集\n",
    "    :return : [list] 所有频繁项集的集合\n",
    "              [dict] 所有候选项集的支持度，在计算可信度用到\n",
    "    '''\n",
    "    # 1. 从数据集得到物品列表与大小为 1 的频繁项集的集合(同上一模块的代码)\n",
    "    C1 = createC1(dataset)\n",
    "    D = list(map(set, dataset))  # 每条交易记录去重，我们不关心物品的数量\n",
    "    L1, support_data = scanD(D, C1, 0.5)  # 保留每一个候选项集的支持度\n",
    "    L = [L1]  # 保存每层的频繁项集集合的列表\n",
    "    k = 2  # 代表层数，即项集的大小\n",
    "    \n",
    "    # 2. 当集合中项的个数大于 0 时\n",
    "    while len(L[k-2]) > 0:\n",
    "        # 3. 构建一个大小为 k 的候选项集的集合\n",
    "        Ck = apriori_gen(L[k-2], k)\n",
    "        # 4. 根据 Ck 生成大小为 k 的频繁项集的集合\n",
    "        Lk, supK = scanD(D, Ck, min_support)\n",
    "        support_data.update(supK)  # 保留每一个候选项集的支持度\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    \n",
    "    return L, support_data\n",
    "\n",
    "dataset = [[1,3,4],[2,3,5],[1,2,3,5],[2,5]]\n",
    "L, support_data = apriori(dataset)\n",
    "print(L)\n",
    "print(support_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 从频繁项集中挖掘关联规则\n",
    "\n",
    "比如，一个频繁项集为 {0,1,2,3}，它的关联规则如下： ![一个频繁项集生成关联规则的示例图](./一个频繁项集生成关联规则的示例图.png) 计算每个关联规则的可信度。可信度超过最小要求，则保留该关联规则\n",
    "\n",
    "从上图可见，不采用一定的剪枝操作，会出现跟全组合那样的计算时间指数式增长。\n",
    "\n",
    "**剪枝操作**：Apriori 原理。当某条规则不满足最小可信度要求，那么该规则的所有子集也不满足要求。如图中 \"012->3\" 不满足要求，那么它的子集 \"12->03\", \"02->13\", \"01->23\",... 都一定不满足要求。\n",
    "\n",
    "**可信度的计算**：(\"P->H\")的可信度 = 所有出现在集合P或者集合Q中的元素的支持度 / 频繁项集 P 的支持度（FIXME）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({1})-->frozenset({3}),conf:1.0\n",
      "frozenset({5})-->frozenset({2}),conf:1.0\n",
      "frozenset({2})-->frozenset({5}),conf:1.0\n",
      "=============\n",
      "frozenset({3})-->frozenset({1}),conf:0.6666666666666666\n",
      "frozenset({1})-->frozenset({3}),conf:1.0\n",
      "frozenset({3})-->frozenset({2}),conf:0.6666666666666666\n",
      "frozenset({2})-->frozenset({3}),conf:0.6666666666666666\n",
      "frozenset({5})-->frozenset({2}),conf:1.0\n",
      "frozenset({2})-->frozenset({5}),conf:1.0\n",
      "frozenset({5})-->frozenset({3}),conf:0.6666666666666666\n",
      "frozenset({3})-->frozenset({5}),conf:0.6666666666666666\n",
      "frozenset({5})-->frozenset({2, 3}),conf:0.6666666666666666\n",
      "frozenset({3})-->frozenset({2, 5}),conf:0.6666666666666666\n",
      "frozenset({2})-->frozenset({3, 5}),conf:0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "def generate_rules(L, support_data, min_conf=0.7):\n",
    "    '''\n",
    "    生成关联规则\n",
    "    :param L: [list] 所有的频繁项集的列表。二维列表，第 k 行代表大小为 k 的频繁项集的集合\n",
    "    :param support_data: [dict] 所有项集的支持度\n",
    "    :param min_conf: [float] 最小可信度的要求\n",
    "    :return : [list] 所有的符合要求的关联规则\n",
    "    '''\n",
    "    rule_list = []\n",
    "    for i in range(1, len(L)):  # 便利每层的频繁项集的集合\n",
    "        for freqset in L[i]:  # 遍历第i层的每个频繁项集\n",
    "            H1 = [frozenset([item]) for item in freqset]\n",
    "            if i> 1:\n",
    "                rules_from_conseq(freqset, H1, support_data, rule_list, min_conf)\n",
    "            else:\n",
    "                cal_conf(freqset, H1, support_data, rule_list, min_conf)\n",
    "    return rule_list\n",
    "\n",
    "def cal_conf(freqset, H, support_data, br1, min_conf=0.7):\n",
    "    prunedH = []\n",
    "    for conseq in H:\n",
    "        conf = support_data[freqset] / support_data[freqset - conseq]\n",
    "        if conf >= min_conf:\n",
    "            print('{}-->{},conf:{}'.format(freqset-conseq, conseq, conf))\n",
    "            br1.append((freqset-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH\n",
    "\n",
    "def rules_from_conseq(freqset, H, support_data, br1, min_conf=0.7):\n",
    "    m = len(H[0])\n",
    "    if len(freqset) > (m+1):\n",
    "        Hmp1 = apriori_gen(H, m+1)\n",
    "        Hmp1 = cal_conf(freqset, Hmp1, support_data, br1, min_conf)\n",
    "        if len(Hmp1) > 1:\n",
    "            rules_from_conseq(freqset, Hmp1, support_data, br1, min_conf)\n",
    "            \n",
    "            \n",
    "dataset = [[1,3,4],[2,3,5],[1,2,3,5],[2,5]]\n",
    "L, support_data = apriori(dataset)\n",
    "rules_07 = generate_rules(L, support_data, min_conf=0.7)\n",
    "print('=============')\n",
    "rules_05 = generate_rules(L, support_data, min_conf=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
